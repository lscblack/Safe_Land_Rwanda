# Model Deployment Guide

## Loading the Trained Model

This guide shows how to use the saved price prediction model in your applications.

### 1. Load the Model and Preprocessors

```python
import joblib
import numpy as np
import pandas as pd

# Load the trained model
model = joblib.load('saved_models/gradient_boosting_price_model.pkl')

# Load preprocessing tools
scaler = joblib.load('saved_models/feature_scaler.pkl')
encoders = joblib.load('saved_models/label_encoders.pkl')
features = joblib.load('saved_models/feature_names.pkl')
metadata = joblib.load('saved_models/model_metadata.pkl')

# Access encoders
le_province = encoders['province']
le_district = encoders['district']
le_transaction = encoders['transaction']

print("Model loaded successfully!")
print(f"Model Type: {metadata['model_type']}")
print(f"RÂ² Score: {metadata['r2_score']:.4f}")
print(f"RMSE: {metadata['rmse']:,.2f} RWF")
```

### 2. Make Predictions

```python
def predict_land_price(province, district, size_sqm, latitude, longitude, 
                       transaction_type, year=2026, month=1):
    """
    Predict land price for a specific property
    
    Parameters:
    -----------
    province : str - Province name
    district : str - District name
    size_sqm : int - Land size in square meters
    latitude : float - Geographic latitude
    longitude : float - Geographic longitude
    transaction_type : str - Type of transaction
    year : int - Year (default: 2026)
    month : int - Month (default: 1)
    
    Returns:
    --------
    dict - Prediction results with price and confidence
    """
    
    try:
        # Encode categorical features
        province_enc = le_province.transform([province])[0]
        district_enc = le_district.transform([district])[0]
        transaction_enc = le_transaction.transform([transaction_type])[0]
        
        # Create feature array in correct order
        feature_array = np.array([[
            size_sqm,
            latitude,
            longitude,
            province_enc,
            district_enc,
            transaction_enc,
            year,
            month
        ]])
        
        # Scale features using saved scaler
        feature_scaled = scaler.transform(feature_array)
        
        # Make prediction
        predicted_price = model.predict(feature_scaled)[0]
        
        # Calculate confidence interval
        rmse = metadata['rmse']
        confidence_lower = predicted_price - rmse
        confidence_upper = predicted_price + rmse
        
        return {
            'status': 'success',
            'predicted_price': int(predicted_price),
            'confidence_interval': {
                'lower': int(confidence_lower),
                'upper': int(confidence_upper)
            },
            'currency': 'RWF',
            'model_version': '1.0'
        }
        
    except Exception as e:
        return {
            'status': 'error',
            'message': str(e)
        }

# Example usage
result = predict_land_price(
    province='Eastern',
    district='Bugesera',
    size_sqm=500,
    latitude=-1.9441,
    longitude=30.0619,
    transaction_type='Transfer by Voluntary Sale'
)

print(f"Predicted Price: {result['predicted_price']:,} {result['currency']}")
print(f"Confidence Range: {result['confidence_interval']['lower']:,} - {result['confidence_interval']['upper']:,}")
```

### 3. Load Cleaned Data

```python
# Load processed datasets
processed_data = pd.read_csv('cleaned_data/processed_data.csv')
training_data = pd.read_csv('cleaned_data/training_features.csv')
test_data = pd.read_csv('cleaned_data/test_features.csv')

print(f"Total records: {len(processed_data)}")
print(f"Training samples: {len(training_data)}")
print(f"Test samples: {len(test_data)}")

# View sample data
print(processed_data.head())
```

### 4. Batch Predictions

```python
def predict_multiple_properties(properties_df):
    """
    Predict prices for multiple properties
    
    Parameters:
    -----------
    properties_df : DataFrame with columns:
        - province, district, size, latitude, longitude, transaction_type
    
    Returns:
    --------
    DataFrame with original data + predictions
    """
    
    predictions = []
    
    for idx, row in properties_df.iterrows():
        result = predict_land_price(
            province=row['province'],
            district=row['district'],
            size_sqm=row['size'],
            latitude=row['latitude'],
            longitude=row['longitude'],
            transaction_type=row['transaction_type']
        )
        
        predictions.append({
            'property_id': idx,
            **result
        })
    
    return pd.DataFrame(predictions)

# Example: Predict batch of properties
batch_data = pd.DataFrame([
    {
        'province': 'Eastern',
        'district': 'Bugesera',
        'size': 500,
        'latitude': -1.9441,
        'longitude': 30.0619,
        'transaction_type': 'Transfer by Voluntary Sale'
    },
    {
        'province': 'Western',
        'district': 'Nyaruguru',
        'size': 1000,
        'latitude': -2.5,
        'longitude': 29.5,
        'transaction_type': 'Sale'
    },
    {
        'province': 'Kigali',
        'district': 'Kicukiro',
        'size': 300,
        'latitude': -1.9441,
        'longitude': 30.0619,
        'transaction_type': 'Transfer by Voluntary Sale'
    }
])

batch_results = predict_multiple_properties(batch_data)
print(batch_results)
```

### 5. API Endpoint Example (FastAPI)

```python
from fastapi import FastAPI
from pydantic import BaseModel
import joblib

app = FastAPI(title="Safe Land Rwanda - Price Prediction API")

# Load model at startup
model = joblib.load('saved_models/gradient_boosting_price_model.pkl')
scaler = joblib.load('saved_models/feature_scaler.pkl')
encoders = joblib.load('saved_models/label_encoders.pkl')

class PropertyData(BaseModel):
    province: str
    district: str
    size: int
    latitude: float
    longitude: float
    transaction_type: str
    year: int = 2026
    month: int = 1

@app.post("/predict")
async def predict_price(property_data: PropertyData):
    """Predict land price based on property features"""
    
    try:
        # Encode categorical features
        le_prov = encoders['province']
        le_dist = encoders['district']
        le_trans = encoders['transaction']
        
        province_enc = le_prov.transform([property_data.province])[0]
        district_enc = le_dist.transform([property_data.district])[0]
        transaction_enc = le_trans.transform([property_data.transaction_type])[0]
        
        # Create and scale features
        features = np.array([[
            property_data.size,
            property_data.latitude,
            property_data.longitude,
            province_enc,
            district_enc,
            transaction_enc,
            property_data.year,
            property_data.month
        ]])
        
        features_scaled = scaler.transform(features)
        
        # Predict
        predicted_price = model.predict(features_scaled)[0]
        
        return {
            'success': True,
            'predicted_price': int(predicted_price),
            'currency': 'RWF',
            'property': property_data.dict()
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

# Run with: uvicorn app:app --reload
```

### 6. Web Application Integration (Flask)

```python
from flask import Flask, request, jsonify
import joblib

app = Flask(__name__)

# Load model
model = joblib.load('saved_models/gradient_boosting_price_model.pkl')
scaler = joblib.load('saved_models/feature_scaler.pkl')
encoders = joblib.load('saved_models/label_encoders.pkl')

@app.route('/api/predict', methods=['POST'])
def api_predict():
    """API endpoint for price prediction"""
    
    data = request.get_json()
    
    try:
        # Extract features
        province = data['province']
        district = data['district']
        size = data['size']
        latitude = data['latitude']
        longitude = data['longitude']
        transaction_type = data['transaction_type']
        year = data.get('year', 2026)
        month = data.get('month', 1)
        
        # Encode and scale
        province_enc = encoders['province'].transform([province])[0]
        district_enc = encoders['district'].transform([district])[0]
        trans_enc = encoders['transaction'].transform([transaction_type])[0]
        
        features = np.array([[size, latitude, longitude, province_enc, 
                            district_enc, trans_enc, year, month]])
        features_scaled = scaler.transform(features)
        
        # Predict
        price = model.predict(features_scaled)[0]
        
        return jsonify({
            'success': True,
            'predicted_price': int(price),
            'currency': 'RWF'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 400

if __name__ == '__main__':
    app.run(debug=True)
```

## Model Information

- **Model Type**: Gradient Boosting Regressor
- **Training Date**: January 2026
- **Features**: 8 (size, latitude, longitude, province, district, transaction_type, year, month)
- **Training Samples**: Varies by dataset
- **Prediction Range**: Property-specific based on market data

## Error Handling

The model handles these scenarios:

1. **Unknown Province/District**: Will raise error during encoding
2. **Invalid Transaction Type**: Will raise error during encoding
3. **Out-of-range Coordinates**: Model will still predict (use caution)
4. **Negative or Zero Size**: Model will still predict (validate input)

## Performance Characteristics

- **Prediction Speed**: <1ms per property
- **Memory Usage**: ~50MB for loaded model
- **Batch Processing**: Can predict 10,000+ properties per minute

## Maintenance

- Retrain model quarterly with new data
- Monitor prediction accuracy against actual sales
- Update feature encoders when new categories appear
- Review and update RMSE confidence intervals annually

---

For questions or issues, refer to the main README.md in the models directory.
